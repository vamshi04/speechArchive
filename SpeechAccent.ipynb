{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     #excel, csv\n",
    "import seaborn as sns    #visualisation, charts\n",
    "import numpy as np      #broadcasting (apply logic to every element in np arrays and they are superafast)\n",
    "import matplotlib.pyplot as plt #visulisation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Voice Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24407 entries, 48 to 346837\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   client_id   24407 non-null  object \n",
      " 1   path        24407 non-null  object \n",
      " 2   sentence    24407 non-null  object \n",
      " 3   up_votes    24407 non-null  int64  \n",
      " 4   down_votes  24407 non-null  int64  \n",
      " 5   age         24363 non-null  object \n",
      " 6   gender      24384 non-null  object \n",
      " 7   accent      24407 non-null  object \n",
      " 8   locale      24407 non-null  object \n",
      " 9   segment     0 non-null      float64\n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/vamshi/project/CV/CV/en/train.tsv\", sep='\\t')\n",
    "#remove up_votes condition later\n",
    "train_df = df[(df.accent =='indian')]\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 343 entries, 125 to 16017\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   client_id   343 non-null    object\n",
      " 1   path        343 non-null    object\n",
      " 2   sentence    343 non-null    object\n",
      " 3   up_votes    343 non-null    int64 \n",
      " 4   down_votes  343 non-null    int64 \n",
      " 5   age         343 non-null    object\n",
      " 6   gender      341 non-null    object\n",
      " 7   accent      343 non-null    object\n",
      " 8   locale      343 non-null    object\n",
      " 9   segment     1 non-null      object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 29.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"/home/vamshi/project/CV/CV/en/test.tsv\", sep='\\t')\n",
    "test_df = df2[df2.accent =='indian']\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45678 entries, 127 to 995700\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   client_id   45678 non-null  object\n",
      " 1   path        45678 non-null  object\n",
      " 2   sentence    45678 non-null  object\n",
      " 3   up_votes    45678 non-null  int64 \n",
      " 4   down_votes  45678 non-null  int64 \n",
      " 5   age         45574 non-null  object\n",
      " 6   gender      45602 non-null  object\n",
      " 7   accent      45678 non-null  object\n",
      " 8   locale      45678 non-null  object\n",
      " 9   segment     750 non-null    object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 3.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 264932 entries, 57 to 1064735\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   client_id   264932 non-null  object\n",
      " 1   path        264932 non-null  object\n",
      " 2   sentence    264932 non-null  object\n",
      " 3   up_votes    264932 non-null  int64 \n",
      " 4   down_votes  264932 non-null  int64 \n",
      " 5   age         259070 non-null  object\n",
      " 6   gender      260951 non-null  object\n",
      " 7   accent      264932 non-null  object\n",
      " 8   locale      264932 non-null  object\n",
      " 9   segment     3100 non-null    object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 22.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"/home/vamshi/project/CV/CV/en/validated.tsv\", sep='\\t')\n",
    "indian = df3[(df3.accent =='indian')]\n",
    "indian.info()\n",
    "native = df3[(df3.accent =='us')]\n",
    "native.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1318 entries, 0 to 1317\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   sentence     1318 non-null   object\n",
      " 1   sentence_id  1318 non-null   object\n",
      " 2   locale       1318 non-null   object\n",
      " 3   reason       1307 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 41.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"/home/vamshi/project/CV/CV/en/reported.tsv\", sep='\\t')\n",
    "# report_df = df4[(df4.accent =='indian') & (df4.up_votes > 2)]\n",
    "df4.info()\n",
    "# report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'hongkong', 'us', 'england', 'african', 'indian', 'other',\n",
       "       'canada', 'australia', 'scotland', 'philippines', 'singapore',\n",
       "       'bermuda', 'newzealand', 'malaysia', 'ireland', 'wales',\n",
       "       'southatlandtic'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uniques accents:\n",
    "df3['accent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpeechArchive Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59 entries, 20 to 2109\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   age              59 non-null     float64\n",
      " 1   age_onset        59 non-null     float64\n",
      " 2   birthplace       59 non-null     object \n",
      " 3   filename         59 non-null     object \n",
      " 4   native_language  59 non-null     object \n",
      " 5   sex              59 non-null     object \n",
      " 6   speakerid        59 non-null     int64  \n",
      " 7   country          59 non-null     object \n",
      " 8   file_missing?    59 non-null     bool   \n",
      " 9   Unnamed: 9       0 non-null      float64\n",
      " 10  Unnamed: 10      0 non-null      float64\n",
      " 11  Unnamed: 11      0 non-null      object \n",
      "dtypes: bool(1), float64(4), int64(1), object(6)\n",
      "memory usage: 5.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 579 entries, 363 to 941\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   age              579 non-null    float64\n",
      " 1   age_onset        579 non-null    float64\n",
      " 2   birthplace       579 non-null    object \n",
      " 3   filename         579 non-null    object \n",
      " 4   native_language  579 non-null    object \n",
      " 5   sex              579 non-null    object \n",
      " 6   speakerid        579 non-null    int64  \n",
      " 7   country          579 non-null    object \n",
      " 8   file_missing?    579 non-null    bool   \n",
      " 9   Unnamed: 9       0 non-null      float64\n",
      " 10  Unnamed: 10      0 non-null      float64\n",
      " 11  Unnamed: 11      0 non-null      object \n",
      "dtypes: bool(1), float64(4), int64(1), object(6)\n",
      "memory usage: 54.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"/home/vamshi/project/SpeechArchive/speakers_all.csv\")\n",
    "indian = df5[(df5.country =='india')]\n",
    "indian.info()\n",
    "# df5['country'].unique()\n",
    "native = df5[df5.native_language == 'english']\n",
    "native.info()\n",
    "# df5['native_language'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert mp3 to wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speech Archive Dataset \n",
    "\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "# from google.cloud import speech \n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_mp3_wav(filename):\n",
    "    missing_files = []\n",
    "    fpath = Path(\"/home/vamshi/project/SpeechArchive/recordings/recordings/\" + filename + \".mp3\")\n",
    "#     fpath = Path(\"/home/vamshi/project/CV/CV/en/clips/\" + filename)\n",
    "    #     print(fpath)\n",
    "    if fpath.is_file():\n",
    "    #         print(fpath)\n",
    "        sound = AudioSegment.from_mp3(fpath)\n",
    "#         sound.export(\"/home/vamshi/project/CV/CV/en/wav/\" + filename.strip(\".mp3\") + \".wav\", format=\"wav\")\n",
    "\n",
    "        sound.export(\"/home/vamshi/project/SpeechArchive/recordings/wav/\" + filename + \".wav\", format=\"wav\")\n",
    "    else:\n",
    "        print(\"File Doesnot exist\", filename)\n",
    "        missing_files.append(filename)\n",
    "    return missing_files\n",
    "# convert_mp3_wav(indian['filename'])\n",
    "\n",
    "# native['filename'].apply(convert_mp3_wav)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# src = \"\"cd \n",
    "native['filename'].apply(convert_mp3_wav)\n",
    "# indian['path'].apply(convert_mp3_wav)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'missing_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-55a7725d2c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"file_missing?\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"file_missing\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnative\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_missing\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'missing_files' is not defined"
     ]
    }
   ],
   "source": [
    "print(missing_files)\n",
    "native.rename(columns={\"file_missing?\": \"file_missing\"})\n",
    "native.info()\n",
    "native = native[native.file_missing != True]\n",
    "native.info()\n",
    "# indian.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#convert to wav\n",
    "# convert_mp3_wav()\n",
    "\n",
    "#googple Speech API \n",
    "# transcribe_gcs_with_word_time_offsets()\n",
    "\n",
    "#append transcribe and word info columns to dataframe\n",
    "# def wordInfo:\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# df_copy = report_df[:]\n",
    "\n",
    "#\n",
    "\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/vamshi/LastSem/DLWithPython/finalProject-1cbe5aadc559.json\"\n",
    "print(transcribe_gcs_with_word_time_offsets(\"bengali11\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_gcs_with_word_time_offsets(filename):\n",
    "    \"\"\"Transcribe the given audio file asynchronously and output the word time\n",
    "    offsets.\"\"\"\n",
    "    from google.cloud import speech_v1p1beta1 as speech\n",
    "    from pathlib import Path\n",
    "    \n",
    "    fpath = Path(\"/home/vamshi/project/SpeechArchive/recordings/wav/\" + filename + \".wav\")\n",
    "    \n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "#     speech_file = \"resources/Google_Gnome.wav\"\n",
    "\n",
    "    with open(fpath, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    #     sample_rate_hertz=16000,                #\n",
    "        language_code=\"en-US\",\n",
    "        enable_word_confidence=True,\n",
    "        enable_word_time_offsets=True\n",
    "\n",
    "    )\n",
    "\n",
    "#     operation = client.long_running_recognize(\n",
    "#         request={\"config\": config, \"audio\": audio}\n",
    "#     )\n",
    "    \n",
    "    return response = client.recognize(request={\"config\": config, \"audio\": audio})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i, result in enumerate(response.results):\n",
    "#     alternative = result.alternatives[0]\n",
    "#     print(\"-\" * 20)\n",
    "#     print(\"word_info\",alternative.words)\n",
    "#     temp = i\n",
    "# print(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>please</th>\n",
       "      <th>call</th>\n",
       "      <th>Stella</th>\n",
       "      <th>ask</th>\n",
       "      <th>her</th>\n",
       "      <th>to</th>\n",
       "      <th>bring</th>\n",
       "      <th>these</th>\n",
       "      <th>things</th>\n",
       "      <th>...</th>\n",
       "      <th>snow</th>\n",
       "      <th>peas</th>\n",
       "      <th>leaves</th>\n",
       "      <th>screw</th>\n",
       "      <th>into</th>\n",
       "      <th>three</th>\n",
       "      <th>red</th>\n",
       "      <th>Red</th>\n",
       "      <th>Nose</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bengali14</td>\n",
       "      <td>[(0.6, 1.2)]</td>\n",
       "      <td>[(1.2, 1.4)]</td>\n",
       "      <td>[(1.4, 1.7)]</td>\n",
       "      <td>[(1.7, 2.6)]</td>\n",
       "      <td>[(2.6, 2.8), (21.2, 21.3)]</td>\n",
       "      <td>[(2.8, 2.9)]</td>\n",
       "      <td>[(2.9, 3.1)]</td>\n",
       "      <td>[(3.1, 3.4)]</td>\n",
       "      <td>[(3.4, 3.7)]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bengali9</td>\n",
       "      <td>[(0.19999999999999998, 1.0)]</td>\n",
       "      <td>[(1.0, 1.4)]</td>\n",
       "      <td>[(1.4, 1.7999999999999998)]</td>\n",
       "      <td>[(1.7999999999999998, 2.8)]</td>\n",
       "      <td>[(2.8, 3.0), (4.6, 4.8), (14.2, 14.5)]</td>\n",
       "      <td>[(3.0, 3.3)]</td>\n",
       "      <td>[(3.3, 3.4)]</td>\n",
       "      <td>[(3.4, 3.8)]</td>\n",
       "      <td>[(3.8, 4.3), (23.4, 24.3)]</td>\n",
       "      <td>...</td>\n",
       "      <td>[(7.8, 8.1)]</td>\n",
       "      <td>[(8.1, 8.6)]</td>\n",
       "      <td>[(8.6, 10.5)]</td>\n",
       "      <td>[(22.7, 23.4)]</td>\n",
       "      <td>[(24.3, 25.0)]</td>\n",
       "      <td>[(25.0, 25.7)]</td>\n",
       "      <td>[(25.7, 26.3)]</td>\n",
       "      <td>[(29.1, 29.3)]</td>\n",
       "      <td>[(29.3, 29.6)]</td>\n",
       "      <td>[(29.6, 29.7)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker_id                        please          call  \\\n",
       "0  bengali14                  [(0.6, 1.2)]  [(1.2, 1.4)]   \n",
       "1   bengali9  [(0.19999999999999998, 1.0)]  [(1.0, 1.4)]   \n",
       "\n",
       "                        Stella                          ask  \\\n",
       "0                 [(1.4, 1.7)]                 [(1.7, 2.6)]   \n",
       "1  [(1.4, 1.7999999999999998)]  [(1.7999999999999998, 2.8)]   \n",
       "\n",
       "                                      her            to         bring  \\\n",
       "0              [(2.6, 2.8), (21.2, 21.3)]  [(2.8, 2.9)]  [(2.9, 3.1)]   \n",
       "1  [(2.8, 3.0), (4.6, 4.8), (14.2, 14.5)]  [(3.0, 3.3)]  [(3.3, 3.4)]   \n",
       "\n",
       "          these                      things  ...          snow          peas  \\\n",
       "0  [(3.1, 3.4)]                [(3.4, 3.7)]  ...           NaN           NaN   \n",
       "1  [(3.4, 3.8)]  [(3.8, 4.3), (23.4, 24.3)]  ...  [(7.8, 8.1)]  [(8.1, 8.6)]   \n",
       "\n",
       "          leaves           screw            into           three  \\\n",
       "0            NaN             NaN             NaN             NaN   \n",
       "1  [(8.6, 10.5)]  [(22.7, 23.4)]  [(24.3, 25.0)]  [(25.0, 25.7)]   \n",
       "\n",
       "              red             Red            Nose             Day  \n",
       "0             NaN             NaN             NaN             NaN  \n",
       "1  [(25.7, 26.3)]  [(29.1, 29.3)]  [(29.3, 29.6)]  [(29.6, 29.7)]  \n",
       "\n",
       "[2 rows x 71 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word_Class.transcribe_gcs_with_word_time_offsets\n",
    "# print(response)\n",
    "\n",
    "#     print(response)\n",
    "response, filename = transcribe_gcs_with_word_time_offsets(\"bengali9\")\n",
    "\n",
    "dict_as =  Word_Class.add_word_info(response, filename)\n",
    "\n",
    "\n",
    "\n",
    "# def concat_df(word_dic):\n",
    "#     if global_df.empty:\n",
    "#         print(\"empty\")\n",
    "#         global_df = pd.DataFrame.from_dict(word_dic, orient='index')\n",
    "#         global_df = global_df.transpose()\n",
    "#     else:\n",
    "#         global_df.head()\n",
    "#         temp = pd.DataFrame.from_dict(word_dic, orient='index')\n",
    "#         temp = temp.transpose()\n",
    "#         global_df = pd.concat([global_df,temp], axis=0, ignore_index=True)\n",
    "#     return global_df\n",
    "final_df = Word_Class.concat_df(dict_as)\n",
    "final_df.head()\n",
    "# df1 = pd.DataFrame.from_dict(dict_as, orient='index')\n",
    "\n",
    "# dft1 = df1.transpose()\n",
    "# df3 = pd.concat([dft,dft1], axis=0, ignore_index=True)\n",
    "# df3.head()\n",
    "\n",
    "# to do:\n",
    "\n",
    "\n",
    "# create nested dictionary with filename and wordinfo included:\n",
    "# {please: {fname1: [(strt,end),(strt, end)]}, {fname2: [(strt, end)]}}\n",
    "\n",
    "\n",
    "# change add_wordInfo function while looping through words using : \n",
    "# https://stackoverflow.com/questions/26827081/create-nested-dictionaries-with-for-loop-in-python\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "# word_np = np.array() # size = (max(repetation of a word)) x (no. of words)\n",
    "\n",
    "# word_np \n",
    "\n",
    "class Word_Info:\n",
    "     #{ word1: [(start, end), (start, end), (start, end)], \\\n",
    "                   #  word2: [(start, end), (start, end), (start, end)], . . . . . \n",
    "                   # }\n",
    "    # def __init__(self, )\n",
    "    global_df = pd.DataFrame()\n",
    "    missingFiles = []\n",
    "    def transcribe_gcs_with_word_time_offsets(self, filename):\n",
    "        client = speech.SpeechClient()\n",
    "\n",
    "        speech_file = Path(\"/home/vamshi/project/SpeechArchive/recordings/wav/\" + filename + \".wav\")\n",
    "        if speech_file.exists ():                              # put a check point after the function call (explicit) \n",
    "            with open(speech_file, \"rb\") as audio_file:\n",
    "                content = audio_file.read()\n",
    "\n",
    "            audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "            config = speech.RecognitionConfig(\n",
    "                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "            #     sample_rate_hertz=16000,\n",
    "                language_code=\"en-US\",\n",
    "                enable_word_confidence=True,\n",
    "                enable_word_time_offsets=True\n",
    "\n",
    "            )\n",
    "\n",
    "            response = client.recognize(request={\"config\": config, \"audio\": audio})\n",
    "            temp = 0\n",
    "\n",
    "\n",
    "            word_dict = {}\n",
    "            word_dict[\"speaker_id\"] = filename\n",
    "            for result in response.results:\n",
    "                alternative = result.alternatives[0]\n",
    "    #             print(alternative.words)\n",
    "\n",
    "                for word in alternative.words:\n",
    "    #                 print(word)\n",
    "    #                 fname = {filename:[]}\n",
    "                    word_str = str(word.word)\n",
    "                    start = float(word.start_time.seconds + (10 ** -6 * (word.start_time.microseconds)))\n",
    "                    end = float(word.end_time.seconds + (10 ** -6 * (word.end_time.microseconds)))\n",
    "                    conf = float(word.confidence)\n",
    "    #                 speaker[str(filename)] \n",
    "\n",
    "                    if word_str in word_dict:\n",
    "                        # print(\"word_str: \", type(self.word_dict[word_str])) \n",
    "                        word_dict[word_str].append((start, end, conf))\n",
    "                    else:\n",
    "                        word_dict[word_str] = [(start, end, conf)] \n",
    "                    # print(u\"Word: {}, start: {} , end: {}\".format(word.word, \\\n",
    "                    # word.start_time.seconds + (10 ** -9 * (word.start_time.nanos)),\\\n",
    "                    # word.end_time.seconds + (10 ** -9 * (word.end_time.nanos))))\n",
    "    #         word_pd = pd.DataFrame.from_dict(self.word_dict)\n",
    "\n",
    "            if self.global_df.empty:\n",
    "                print(\"empty\")\n",
    "                self.global_df = pd.DataFrame.from_dict(word_dict, orient='index')\n",
    "                self.global_df = self.global_df.transpose()\n",
    "            else:\n",
    "                self.global_df.head()\n",
    "                temp = pd.DataFrame.from_dict(word_dict, orient='index')\n",
    "                temp = temp.transpose()\n",
    "                self.global_df = pd.concat([self.global_df,temp], axis=0, ignore_index=True)\n",
    "        else:\n",
    "            self.missingFiles.append(filename)\n",
    "            \n",
    "            return self.global_df, self.missingFiles\n",
    "    \n",
    "    def add_word_info(self, response, filename):\n",
    "        word_dict = {}\n",
    "        word_dict[\"speaker_id\"] = filename\n",
    "        for result in response.results:\n",
    "            alternative = result.alternatives[0]\n",
    "#             print(alternative.words)\n",
    "            \n",
    "            for word in alternative.words:\n",
    "#                 print(word)\n",
    "#                 fname = {filename:[]}\n",
    "                word_str = str(word.word)\n",
    "                start = float(word.start_time.seconds + (10 ** -6 * (word.start_time.microseconds)))\n",
    "                end = float(word.end_time.seconds + (10 ** -6 * (word.end_time.microseconds)))\n",
    "#                 speaker[str(filename)] \n",
    "\n",
    "                if word_str in word_dict:\n",
    "                    # print(\"word_str: \", type(self.word_dict[word_str])) \n",
    "                    word_dict[word_str].append((start, end))\n",
    "                else:\n",
    "                    word_dict[word_str] = [(start, end)] \n",
    "                # print(u\"Word: {}, start: {} , end: {}\".format(word.word, \\\n",
    "                # word.start_time.seconds + (10 ** -9 * (word.start_time.nanos)),\\\n",
    "                # word.end_time.seconds + (10 ** -9 * (word.end_time.nanos))))\n",
    "#         word_pd = pd.DataFrame.from_dict(self.word_dict)\n",
    "\n",
    "        return word_dict\n",
    "\n",
    "    def concat_df(self, word_dic):\n",
    "        if self.global_df.empty:\n",
    "            print(\"empty\")\n",
    "            self.global_df = pd.DataFrame.from_dict(word_dic, orient='index')\n",
    "            self.global_df = self.global_df.transpose()\n",
    "        else:\n",
    "            self.global_df.head()\n",
    "            temp = pd.DataFrame.from_dict(word_dic, orient='index')\n",
    "            temp = temp.transpose()\n",
    "            self.global_df = pd.concat([self.global_df,temp], axis=0, ignore_index=True)\n",
    "        return self.global_df\n",
    "# Word_Class = Word_Info()\n",
    "\n",
    "Word_Class = Word_Info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from addWord import addWordDict\n",
    "from transcribe import wordTimeOffsets \n",
    "import pandas as pd\n",
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "# word_np = np.array() # size = (max(repetation of a word)) x (no. of words)\n",
    "\n",
    "# word_np \n",
    "\n",
    "global_df = pd.DataFrame()\n",
    "missingFiles = []\n",
    "\n",
    "class Word_Info:\n",
    "    \n",
    "    def __init__(self, global_df, missingFiles):\n",
    "        self.global_df = global_df\n",
    "        self.missingFiles = missingFiles\n",
    "        \n",
    "    \n",
    "    def wordDf(self, filename):\n",
    "        speech_file = Path(\"/home/vamshi/project/SpeechArchive/recordings/wav/\" + filename + \".wav\")\n",
    "        if speech_file.exists ():\n",
    "            response = wordTimeOffsets(selffilename)\n",
    "            temp = 0\n",
    "            word_dict = addWordDict(response, filename)\n",
    "\n",
    "            if self.global_df.empty:\n",
    "                print(\"empty\")\n",
    "                self.global_df = pd.DataFrame.from_dict(word_dict, orient='index')\n",
    "                self.global_df = self.global_df.transpose()\n",
    "            else:\n",
    "                self.global_df.head()\n",
    "                temp = pd.DataFrame.from_dict(word_dict, orient='index')\n",
    "                temp = temp.transpose()\n",
    "                self.global_df = pd.concat([self.global_df,temp], axis=0, ignore_index=True)\n",
    "        else:\n",
    "            self.missingFiles.append(filename)\n",
    "            \n",
    "        return self.global_df, self.missingFiles\n",
    "\n",
    "    def concat_df(self, word_dic):\n",
    "        if self.global_df.empty:\n",
    "            print(\"empty\")\n",
    "            self.global_df = pd.DataFrame.from_dict(word_dic, orient='index')\n",
    "            self.global_df = self.global_df.transpose()\n",
    "        else:\n",
    "            self.global_df.head()\n",
    "            temp = pd.DataFrame.from_dict(word_dic, orient='index')\n",
    "            temp = temp.transpose()\n",
    "            self.global_df = pd.concat([self.global_df,temp], axis=0, ignore_index=True)\n",
    "        return self.global_df\n",
    "# Word_Class = Word_Info()\n",
    "\n",
    "Word_Class = Word_Info(global_df, missingFiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>please</th>\n",
       "      <th>call</th>\n",
       "      <th>Stella</th>\n",
       "      <th>ask</th>\n",
       "      <th>her</th>\n",
       "      <th>to</th>\n",
       "      <th>bring</th>\n",
       "      <th>these</th>\n",
       "      <th>things</th>\n",
       "      <th>...</th>\n",
       "      <th>snow</th>\n",
       "      <th>peas</th>\n",
       "      <th>laps</th>\n",
       "      <th>Scoobies</th>\n",
       "      <th>into</th>\n",
       "      <th>three</th>\n",
       "      <th>red</th>\n",
       "      <th>would</th>\n",
       "      <th>witness</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bengali14</td>\n",
       "      <td>[(0.6, 1.2)]</td>\n",
       "      <td>[(1.2, 1.4)]</td>\n",
       "      <td>[(1.4, 1.7)]</td>\n",
       "      <td>[(1.7, 2.6)]</td>\n",
       "      <td>[(2.6, 2.8), (21.2, 21.3)]</td>\n",
       "      <td>[(2.8, 2.9)]</td>\n",
       "      <td>[(2.9, 3.1)]</td>\n",
       "      <td>[(3.1, 3.4)]</td>\n",
       "      <td>[(3.4, 3.7)]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bengali6</td>\n",
       "      <td>[(0.3, 0.7999999999999999)]</td>\n",
       "      <td>[(0.7999999999999999, 1.0)]</td>\n",
       "      <td>[(1.0, 1.3)]</td>\n",
       "      <td>[(1.3, 2.1)]</td>\n",
       "      <td>[(2.1, 2.2), (3.1, 3.2), (9.3, 9.4), (18.1, 18...</td>\n",
       "      <td>[(2.2, 2.3)]</td>\n",
       "      <td>[(2.3, 2.4)]</td>\n",
       "      <td>[(2.4, 2.6)]</td>\n",
       "      <td>[(2.6, 2.9), (15.3, 15.7)]</td>\n",
       "      <td>...</td>\n",
       "      <td>[(5.3, 5.6)]</td>\n",
       "      <td>[(5.6, 6.1)]</td>\n",
       "      <td>[(7.1, 7.3)]</td>\n",
       "      <td>[(14.8, 15.3)]</td>\n",
       "      <td>[(15.7, 16.2)]</td>\n",
       "      <td>[(16.2, 16.4)]</td>\n",
       "      <td>[(16.4, 16.6)]</td>\n",
       "      <td>[(17.6, 17.7)]</td>\n",
       "      <td>[(18.2, 18.6)]</td>\n",
       "      <td>[(18.6, 18.8)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker_id                       please                         call  \\\n",
       "0  bengali14                 [(0.6, 1.2)]                 [(1.2, 1.4)]   \n",
       "1   bengali6  [(0.3, 0.7999999999999999)]  [(0.7999999999999999, 1.0)]   \n",
       "\n",
       "         Stella           ask  \\\n",
       "0  [(1.4, 1.7)]  [(1.7, 2.6)]   \n",
       "1  [(1.0, 1.3)]  [(1.3, 2.1)]   \n",
       "\n",
       "                                                 her            to  \\\n",
       "0                         [(2.6, 2.8), (21.2, 21.3)]  [(2.8, 2.9)]   \n",
       "1  [(2.1, 2.2), (3.1, 3.2), (9.3, 9.4), (18.1, 18...  [(2.2, 2.3)]   \n",
       "\n",
       "          bring         these                      things  ...          snow  \\\n",
       "0  [(2.9, 3.1)]  [(3.1, 3.4)]                [(3.4, 3.7)]  ...           NaN   \n",
       "1  [(2.3, 2.4)]  [(2.4, 2.6)]  [(2.6, 2.9), (15.3, 15.7)]  ...  [(5.3, 5.6)]   \n",
       "\n",
       "           peas          laps        Scoobies            into           three  \\\n",
       "0           NaN           NaN             NaN             NaN             NaN   \n",
       "1  [(5.6, 6.1)]  [(7.1, 7.3)]  [(14.8, 15.3)]  [(15.7, 16.2)]  [(16.2, 16.4)]   \n",
       "\n",
       "              red           would         witness             day  \n",
       "0             NaN             NaN             NaN             NaN  \n",
       "1  [(16.4, 16.6)]  [(17.6, 17.7)]  [(18.2, 18.6)]  [(18.6, 18.8)]  \n",
       "\n",
       "[2 rows x 71 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word_Class.wordDf(\"bengali6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (<ipython-input-182-892f588b8466>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-182-892f588b8466>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    continue\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    native['filename'].apply(Word_Class.transcribe_gcs_with_word_time_offsets)\n",
    "except FileNotFoundError:\n",
    "        print(\"Wrong file or file path\")\n",
    "else:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "363    None\n",
       "364    None\n",
       "365    None\n",
       "366    None\n",
       "367    None\n",
       "       ... \n",
       "937    None\n",
       "938    None\n",
       "939    None\n",
       "940    None\n",
       "941    None\n",
       "Name: filename, Length: 579, dtype: object"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do this exclusively so that filenames are handles correctly\n",
    "\n",
    "native['filename'].apply(Word_Class.transcribe_gcs_with_word_time_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "# Word_Class.global_df.head()\n",
    "print(len(Word_Class.missingFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_Class.global_df.to_excel (r'/home/vamshi/project/SpeechArchive/recordings/word.xlsx', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognize the words in each audio clip\n",
    "# Postprocess data to figure out bounds of words (example: word was \"Stella\", recognized as \"Bella\",\n",
    "#    has two phonemes, use start/end times of \"Bella\" for \"Stella\")\n",
    "# For each word, extract coefficients\n",
    "# Input to network: coefficients for a word --> Output: English or Indian\n",
    "# Alternative: siamese/one-shot network: input a set of coefficients (same word, BUT could be:\n",
    "# - english english\n",
    "# - english indian\n",
    "# - indian english\n",
    "# - indian indian)\n",
    "# Simple: same or different, OR one of the four combinations above\n",
    "\n",
    "# myInput = Input(shape=(vecLen,))\n",
    "# x = Dense(256, activation=\"relu\")(myInput)\n",
    "# out = Dense(2, activation=\"softmax\")(x)\n",
    "# myModel = Model(inputs=myInput, outputs=out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
