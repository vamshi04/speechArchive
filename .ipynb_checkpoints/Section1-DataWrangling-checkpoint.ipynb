{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     #excel, csv\n",
    "import seaborn as sns    #visualisation, charts\n",
    "import numpy as np      #broadcasting (apply logic to every element in np arrays and they are superafast)\n",
    "import matplotlib.pyplot as plt #visulisation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Voice Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24407 entries, 48 to 346837\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   client_id   24407 non-null  object \n",
      " 1   path        24407 non-null  object \n",
      " 2   sentence    24407 non-null  object \n",
      " 3   up_votes    24407 non-null  int64  \n",
      " 4   down_votes  24407 non-null  int64  \n",
      " 5   age         24363 non-null  object \n",
      " 6   gender      24384 non-null  object \n",
      " 7   accent      24407 non-null  object \n",
      " 8   locale      24407 non-null  object \n",
      " 9   segment     0 non-null      float64\n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/vamshi/project/CV/CV/en/train.tsv\", sep='\\t')\n",
    "#remove up_votes condition later\n",
    "train_df = df[(df.accent =='indian')]\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 343 entries, 125 to 16017\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   client_id   343 non-null    object\n",
      " 1   path        343 non-null    object\n",
      " 2   sentence    343 non-null    object\n",
      " 3   up_votes    343 non-null    int64 \n",
      " 4   down_votes  343 non-null    int64 \n",
      " 5   age         343 non-null    object\n",
      " 6   gender      341 non-null    object\n",
      " 7   accent      343 non-null    object\n",
      " 8   locale      343 non-null    object\n",
      " 9   segment     1 non-null      object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 29.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"/home/vamshi/project/CV/CV/en/test.tsv\", sep='\\t')\n",
    "test_df = df2[df2.accent =='indian']\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45678 entries, 127 to 995700\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   client_id   45678 non-null  object\n",
      " 1   path        45678 non-null  object\n",
      " 2   sentence    45678 non-null  object\n",
      " 3   up_votes    45678 non-null  int64 \n",
      " 4   down_votes  45678 non-null  int64 \n",
      " 5   age         45574 non-null  object\n",
      " 6   gender      45602 non-null  object\n",
      " 7   accent      45678 non-null  object\n",
      " 8   locale      45678 non-null  object\n",
      " 9   segment     750 non-null    object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 3.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 264932 entries, 57 to 1064735\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   client_id   264932 non-null  object\n",
      " 1   path        264932 non-null  object\n",
      " 2   sentence    264932 non-null  object\n",
      " 3   up_votes    264932 non-null  int64 \n",
      " 4   down_votes  264932 non-null  int64 \n",
      " 5   age         259070 non-null  object\n",
      " 6   gender      260951 non-null  object\n",
      " 7   accent      264932 non-null  object\n",
      " 8   locale      264932 non-null  object\n",
      " 9   segment     3100 non-null    object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 22.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"/home/vamshi/project/CV/CV/en/validated.tsv\", sep='\\t')\n",
    "indian = df3[(df3.accent =='indian')]\n",
    "indian.info()\n",
    "native = df3[(df3.accent =='us')]\n",
    "native.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1318 entries, 0 to 1317\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   sentence     1318 non-null   object\n",
      " 1   sentence_id  1318 non-null   object\n",
      " 2   locale       1318 non-null   object\n",
      " 3   reason       1307 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 41.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"/home/vamshi/project/CV/CV/en/reported.tsv\", sep='\\t')\n",
    "# report_df = df4[(df4.accent =='indian') & (df4.up_votes > 2)]\n",
    "df4.info()\n",
    "# report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'hongkong', 'us', 'england', 'african', 'indian', 'other',\n",
       "       'canada', 'australia', 'scotland', 'philippines', 'singapore',\n",
       "       'bermuda', 'newzealand', 'malaysia', 'ireland', 'wales',\n",
       "       'southatlandtic'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uniques accents:\n",
    "df3['accent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpeechArchive Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59 entries, 20 to 2109\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   age              59 non-null     float64\n",
      " 1   age_onset        59 non-null     float64\n",
      " 2   birthplace       59 non-null     object \n",
      " 3   filename         59 non-null     object \n",
      " 4   native_language  59 non-null     object \n",
      " 5   sex              59 non-null     object \n",
      " 6   speakerid        59 non-null     int64  \n",
      " 7   country          59 non-null     object \n",
      " 8   file_missing?    59 non-null     bool   \n",
      " 9   Unnamed: 9       0 non-null      float64\n",
      " 10  Unnamed: 10      0 non-null      float64\n",
      " 11  Unnamed: 11      0 non-null      object \n",
      "dtypes: bool(1), float64(4), int64(1), object(6)\n",
      "memory usage: 5.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 579 entries, 363 to 941\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   age              579 non-null    float64\n",
      " 1   age_onset        579 non-null    float64\n",
      " 2   birthplace       579 non-null    object \n",
      " 3   filename         579 non-null    object \n",
      " 4   native_language  579 non-null    object \n",
      " 5   sex              579 non-null    object \n",
      " 6   speakerid        579 non-null    int64  \n",
      " 7   country          579 non-null    object \n",
      " 8   file_missing?    579 non-null    bool   \n",
      " 9   Unnamed: 9       0 non-null      float64\n",
      " 10  Unnamed: 10      0 non-null      float64\n",
      " 11  Unnamed: 11      0 non-null      object \n",
      "dtypes: bool(1), float64(4), int64(1), object(6)\n",
      "memory usage: 54.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"/home/vamshi/project/SpeechArchive/speakers_all.csv\")\n",
    "indian = df5[(df5.country =='india')]\n",
    "indian.info()\n",
    "# df5['country'].unique()\n",
    "native = df5[df5.native_language == 'english']\n",
    "native.info()\n",
    "# df5['native_language'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert mp3 to wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speech Archive Dataset \n",
    "\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "# from google.cloud import speech \n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_mp3_wav(filename):\n",
    "    missing_files = []\n",
    "    fpath = Path(\"/home/vamshi/project/SpeechArchive/recordings/recordings/\" + filename + \".mp3\")\n",
    "#     fpath = Path(\"/home/vamshi/project/CV/CV/en/clips/\" + filename)\n",
    "    #     print(fpath)\n",
    "    if fpath.is_file():\n",
    "    #         print(fpath)\n",
    "        sound = AudioSegment.from_mp3(fpath)\n",
    "#         sound.export(\"/home/vamshi/project/CV/CV/en/wav/\" + filename.strip(\".mp3\") + \".wav\", format=\"wav\")\n",
    "\n",
    "        sound.export(\"/home/vamshi/project/SpeechArchive/recordings/wav/\" + filename + \".wav\", format=\"wav\")\n",
    "    else:\n",
    "        print(\"File Doesnot exist\", filename)\n",
    "        missing_files.append(filename)\n",
    "    return missing_files\n",
    "# convert_mp3_wav(indian['filename'])\n",
    "\n",
    "# native['filename'].apply(convert_mp3_wav)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# src = \"\"cd \n",
    "native['filename'].apply(convert_mp3_wav)\n",
    "# indian['path'].apply(convert_mp3_wav)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_onset</th>\n",
       "      <th>birthplace</th>\n",
       "      <th>filename</th>\n",
       "      <th>native_language</th>\n",
       "      <th>sex</th>\n",
       "      <th>speakerid</th>\n",
       "      <th>country</th>\n",
       "      <th>file_missing?</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>jammu, kashmir, india</td>\n",
       "      <td>poonchi1</td>\n",
       "      <td>poonchi</td>\n",
       "      <td>male</td>\n",
       "      <td>425</td>\n",
       "      <td>india</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>34.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>durgapur, west bengal, india</td>\n",
       "      <td>bengali11</td>\n",
       "      <td>bengali</td>\n",
       "      <td>male</td>\n",
       "      <td>1018</td>\n",
       "      <td>india</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>kolkata, india</td>\n",
       "      <td>bengali14</td>\n",
       "      <td>bengali</td>\n",
       "      <td>male</td>\n",
       "      <td>1973</td>\n",
       "      <td>india</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>jamshedpur, jharkhand, india</td>\n",
       "      <td>bengali6</td>\n",
       "      <td>bengali</td>\n",
       "      <td>male</td>\n",
       "      <td>624</td>\n",
       "      <td>india</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>kolkata, india</td>\n",
       "      <td>bengali9</td>\n",
       "      <td>bengali</td>\n",
       "      <td>female</td>\n",
       "      <td>987</td>\n",
       "      <td>india</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  age_onset                    birthplace   filename native_language  \\\n",
       "20   25.0        5.0         jammu, kashmir, india   poonchi1         poonchi   \n",
       "205  34.0        3.5  durgapur, west bengal, india  bengali11         bengali   \n",
       "208  26.0        4.0                kolkata, india  bengali14         bengali   \n",
       "216  29.0        4.0  jamshedpur, jharkhand, india   bengali6         bengali   \n",
       "219  61.0       12.0                kolkata, india   bengali9         bengali   \n",
       "\n",
       "        sex  speakerid country  file_missing?  Unnamed: 9  Unnamed: 10  \\\n",
       "20     male        425   india           True         NaN          NaN   \n",
       "205    male       1018   india          False         NaN          NaN   \n",
       "208    male       1973   india          False         NaN          NaN   \n",
       "216    male        624   india          False         NaN          NaN   \n",
       "219  female        987   india          False         NaN          NaN   \n",
       "\n",
       "    Unnamed: 11  \n",
       "20          NaN  \n",
       "205         NaN  \n",
       "208         NaN  \n",
       "216         NaN  \n",
       "219         NaN  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# native.head()\n",
    "indian.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#convert to wav\n",
    "# convert_mp3_wav()\n",
    "\n",
    "#googple Speech API \n",
    "# transcribe_gcs_with_word_time_offsets()\n",
    "\n",
    "#append transcribe and word info columns to dataframe\n",
    "# def wordInfo:\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# df_copy = report_df[:]\n",
    "\n",
    "#\n",
    "\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/home/vamshi/LastSem/DLWithPython/finalProject-1cbe5aadc559.json\"\n",
    "print(transcribe_gcs_with_word_time_offsets(\"bengali11\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_gcs_with_word_time_offsets(filename):\n",
    "    \"\"\"Transcribe the given audio file asynchronously and output the word time\n",
    "    offsets.\"\"\"\n",
    "    from google.cloud import speech_v1p1beta1 as speech\n",
    "    from pathlib import Path\n",
    "    \n",
    "    fpath = Path(\"/home/vamshi/project/SpeechArchive/recordings/wav/\" + filename + \".wav\")\n",
    "    \n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "#     speech_file = \"resources/Google_Gnome.wav\"\n",
    "\n",
    "    with open(fpath, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    #     sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",\n",
    "        enable_word_confidence=True,\n",
    "        enable_word_time_offsets=True\n",
    "\n",
    "    )\n",
    "\n",
    "#     operation = client.long_running_recognize(\n",
    "#         request={\"config\": config, \"audio\": audio}\n",
    "#     )\n",
    "    \n",
    "    return response = client.recognize(request={\"config\": config, \"audio\": audio})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import speech_v1p1beta1 as speech\n",
    "\n",
    "def transcribe_gcs_with_word_time_offsets(filename):\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    speech_file = Path(\"/home/vamshi/project/SpeechArchive/recordings/wav/\" + filename + \".wav\")\n",
    "\n",
    "    with open(speech_file, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    #     sample_rate_hertz=16000,\n",
    "        language_code=\"en-US\",\n",
    "        enable_word_confidence=True,\n",
    "        enable_word_time_offsets=True\n",
    "\n",
    "    )\n",
    "\n",
    "    response = client.recognize(request={\"config\": config, \"audio\": audio})\n",
    "    temp = 0\n",
    "    return response, filename\n",
    "# for i, result in enumerate(response.results):\n",
    "#     alternative = result.alternatives[0]\n",
    "#     print(\"-\" * 20)\n",
    "#     print(\"word_info\",alternative.words)\n",
    "#     temp = i\n",
    "# print(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'global_df' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-657f6bc5d8eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mglobal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mglobal_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_as\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# df1 = pd.DataFrame.from_dict(dict_as, orient='index')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-657f6bc5d8eb>\u001b[0m in \u001b[0;36mconcat_df\u001b[0;34m(word_dic)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconcat_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mglobal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mglobal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'global_df' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# print(response)\n",
    "\n",
    "#     print(response)\n",
    "response, filename = transcribe_gcs_with_word_time_offsets(\"bengali14\")\n",
    "\n",
    "dict_as =  Word_Class.add_word_info(response, filename)\n",
    "\n",
    "\n",
    "\n",
    "# def concat_df(word_dic):\n",
    "#     if global_df.empty:\n",
    "#         print(\"empty\")\n",
    "#         global_df = pd.DataFrame.from_dict(word_dic, orient='index')\n",
    "#         global_df = global_df.transpose()\n",
    "#     else:\n",
    "#         global_df.head()\n",
    "#         temp = pd.DataFrame.from_dict(word_dic, orient='index')\n",
    "#         temp = temp.transpose()\n",
    "#         global_df = pd.concat([global_df,temp], axis=0, ignore_index=True)\n",
    "#     return global_df\n",
    "final_df = concat_df(dict_as)\n",
    "final_df.head()\n",
    "# df1 = pd.DataFrame.from_dict(dict_as, orient='index')\n",
    "\n",
    "# dft1 = df1.transpose()\n",
    "# df3 = pd.concat([dft,dft1], axis=0, ignore_index=True)\n",
    "# df3.head()\n",
    "\n",
    "# to do:\n",
    "\n",
    "\n",
    "# create nested dictionary with filename and wordinfo included:\n",
    "# {please: {fname1: [(strt,end),(strt, end)]}, {fname2: [(strt, end)]}}\n",
    "\n",
    "\n",
    "# change add_wordInfo function while looping through words using : \n",
    "# https://stackoverflow.com/questions/26827081/create-nested-dictionaries-with-for-loop-in-python\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-153-c96f9189afe8>, line 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-153-c96f9189afe8>\"\u001b[0;36m, line \u001b[0;32m50\u001b[0m\n\u001b[0;31m    return self.global_df\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# word_np = np.array() # size = (max(repetation of a word)) x (no. of words)\n",
    "\n",
    "# word_np \n",
    "\n",
    "class Word_Info:\n",
    "     #{ word1: [(start, end), (start, end), (start, end)], \\\n",
    "                   #  word2: [(start, end), (start, end), (start, end)], . . . . . \n",
    "                   # }\n",
    "    # def __init__(self, )\n",
    "    global_df = pd.DataFrame()\n",
    "    def add_word_info(self, response, filename):\n",
    "        word_dict = {}\n",
    "        word_dict[\"speaker_id\"] = filename\n",
    "        for result in response.results:\n",
    "            alternative = result.alternatives[0]\n",
    "#             print(alternative.words)\n",
    "            \n",
    "            for word in alternative.words:\n",
    "#                 print(word)\n",
    "#                 fname = {filename:[]}\n",
    "                word_str = str(word.word)\n",
    "                start = float(word.start_time.seconds + (10 ** -6 * (word.start_time.microseconds)))\n",
    "                end = float(word.end_time.seconds + (10 ** -6 * (word.end_time.microseconds)))\n",
    "#                 speaker[str(filename)] \n",
    "\n",
    "                if word_str in word_dict:\n",
    "                    # print(\"word_str: \", type(self.word_dict[word_str])) \n",
    "                    word_dict[word_str].append((start, end))\n",
    "                else:\n",
    "                    word_dict[word_str] = [(start, end)] \n",
    "                # print(u\"Word: {}, start: {} , end: {}\".format(word.word, \\\n",
    "                # word.start_time.seconds + (10 ** -9 * (word.start_time.nanos)),\\\n",
    "                # word.end_time.seconds + (10 ** -9 * (word.end_time.nanos))))\n",
    "#         word_pd = pd.DataFrame.from_dict(self.word_dict)\n",
    "\n",
    "        return word_dict\n",
    "\n",
    "    def concat_df(word_dic):\n",
    "        if self.global_df.empty:\n",
    "            print(\"empty\")\n",
    "            self.global_df = pd.DataFrame.from_dict(word_dic, orient='index')\n",
    "            self.global_df = self.global_df.transpose()\n",
    "        else:\n",
    "            self.global_df.head()\n",
    "            temp = pd.DataFrame.from_dict(word_dic, orient='index')\n",
    "            temp = temp.transpose()\n",
    "            self.global_df = pd.concat([self.global_df,temp], axis=0, ignore_index=True)\n",
    "    return self.global_df\n",
    "# Word_Class = Word_Info()\n",
    "\n",
    "Word_Class = Word_Info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col_1': [3, 2, 1], 'col_2': ['a', 'b', 'c', 'd']}\n",
    "\n",
    "pd.DataFrame.from_dict(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
